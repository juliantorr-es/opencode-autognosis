{
  "id": "request-transformer.ts-summary-1187aceb",
  "file_path": "/Users/user/opencode-autognosis/reference repos/opencode-openai-codex-auth/lib/request/request-transformer.ts",
  "chunk_type": "summary",
  "content": "# Summary: request-transformer.ts\n\n## File Type\n.ts - TypeScript source file\n\n## Purpose\nPurpose not explicitly documented\n\n## Key Components\n\n### Functions (11)\n- **normalizeModel**: Normalize model name to Codex-supported variants\n\nUses explicit model map for known models, with fallback pattern matching\nfor unknown/custom model names.\n- **getModelConfig**: Extract configuration for a specific model\nMerges global options with model-specific options (model-specific takes precedence)\n- **resolveReasoningConfig**: No documentation found\n- **resolveTextVerbosity**: No documentation found\n- **resolveInclude**: No documentation found\n- **getReasoningConfig**: Configure reasoning parameters based on model variant and user config\n\nNOTE: This plugin follows Codex CLI defaults instead of opencode defaults because:\n- We're accessing the ChatGPT backend API (not OpenAI Platform API)\n- opencode explicitly excludes gpt-5-codex from automatic reasoning configuration\n- Codex CLI has been thoroughly tested against this backend\n- **filterInput**: Filter input array for stateless Codex API (store: false)\n\nTwo transformations needed:\n1. Remove AI SDK-specific items (not supported by Codex API)\n2. Strip IDs from all remaining items (stateless mode)\n\nAI SDK constructs to REMOVE (not in OpenAI Responses API spec):\n- type: \"item_reference\" - AI SDK uses this for server-side state lookup\n\nItems to KEEP (strip IDs):\n- type: \"message\" - Conversation messages (provides context to LLM)\n- type: \"function_call\" - Tool calls from conversation\n- type: \"function_call_output\" - Tool results from conversation\n\nContext is maintained through:\n- Full message history (without IDs)\n- reasoning.encrypted_content (for reasoning continuity)\n- **filterOpenCodeSystemPrompts**: Filter out OpenCode system prompts from input\nUsed in CODEX_MODE to replace OpenCode prompts with Codex-OpenCode bridge\n- **addCodexBridgeMessage**: Add Codex-OpenCode bridge message to input if tools are present\n- **addToolRemapMessage**: Add tool remapping message to input if tools are present\n- **transformRequestBody**: Transform request body for Codex API\n\nNOTE: Configuration follows Codex CLI patterns instead of opencode defaults:\n- opencode sets textVerbosity=\"low\" for gpt-5, but Codex CLI uses \"medium\"\n- opencode excludes gpt-5-codex from reasoning configuration\n- This plugin uses store=false (stateless), requiring encrypted reasoning content\n\n\n\n\n## Dependencies\n- ../logger.js\n- ../prompts/codex.js\n- ../prompts/codex-opencode-bridge.js\n- ../prompts/opencode-codex.js\n- ./helpers/model-map.js\n- ./helpers/input-utils.js\n- ../types.js\n\n## Exports\n- normalizeModel\n- getModelConfig\n- getReasoningConfig\n- filterInput\n- filterOpenCodeSystemPrompts\n- addCodexBridgeMessage\n- addToolRemapMessage\n- transformRequestBody\n\n## Complexity Metrics\n- Lines of code: 532\n- Estimated complexity: 100/100\n\n## Notes\nNo specific notes found",
  "metadata": {
    "created_at": "2026-01-30T05:26:52.302Z",
    "updated_at": "2026-01-30T05:26:52.302Z",
    "hash": "0cc93ff6512039004356ce91e12e89e0e65fd5c552aae4cd029393cc8a5d270b",
    "dependencies": [
      "../logger.js",
      "../prompts/codex.js",
      "../prompts/codex-opencode-bridge.js",
      "../prompts/opencode-codex.js",
      "./helpers/model-map.js",
      "./helpers/input-utils.js",
      "../types.js"
    ],
    "symbols": [
      "normalizeModel",
      "modelId",
      "mappedModel",
      "normalized",
      "getModelConfig",
      "globalOptions",
      "modelOptions",
      "resolveReasoningConfig",
      "providerOpenAI",
      "existingEffort",
      "existingSummary",
      "mergedConfig",
      "resolveTextVerbosity",
      "providerOpenAI",
      "resolveInclude",
      "providerOpenAI",
      "base",
      "include",
      "getReasoningConfig",
      "normalizedName",
      "isGpt52Codex",
      "isGpt52General",
      "isCodexMax",
      "isCodexMini",
      "isCodex",
      "isLightweight",
      "isGpt51General",
      "supportsXhigh",
      "supportsNone",
      "defaultEffort",
      "effort",
      "filterInput",
      "filterOpenCodeSystemPrompts",
      "cachedPrompt",
      "addCodexBridgeMessage",
      "bridgeMessage",
      "addToolRemapMessage",
      "toolRemapMessage",
      "transformRequestBody",
      "originalModel",
      "normalizedModel",
      "lookupModel",
      "modelConfig",
      "originalIds",
      "remainingIds",
      "reasoningConfig"
    ],
    "complexity_score": 100
  }
}